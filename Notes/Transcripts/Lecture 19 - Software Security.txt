So, we have a little bit of time left to talk about security, and I, in some sense, should apologize for talking about security last, because I'm helping to propagate a common a certain myth which is that you can design your program and get it working and then at at the from day one. Now, I don't mean that you do all the security part of your application first and then do everything else after that. I don't mean that. But what I mean is that the initial specs, the requirements, and all that sort of thing, you have to be thinking about security along with all the other stuff that you have to think about. And to some extent this is on you the developer because the customer is going to take it for granted they're just going to assume you know what you're doing you're going to building be building software that's secure or at least secure enough for this application they won't know all the ins and outs of what can go wrong that's your job right so this places and it's a special amount of constraint on you shall we say. It's all too easy to not talk about security issues with your client or your customer. They'll assume you know what you're doing. You'll assume that, well, they don't care all that much about security since they're not telling me much. And then you end up writing the code and at the end you say, oh yeah, we need to worry about security and it's too late. You've built a software architecture that's insecure by design. It's going to take you an incredible amount of work to get it to be relatively safe. You've wasted your customer's money or your own money. So don't be that person. I guess that's sort of the first lesson that I want to give you here about security. So I also should say this is a big deal, or a big field, I should say. We have a whole undergraduate course on computer security that isn't offered enough. And aside from artificial intelligence, computer security is probably the biggest area in sort of practical applications, i.e. job offers and internships and all that sort of thing. We don't tend to talk about them much 'cause the people doing security tend to not be blabbermouths, but it's a big area in real world sort of software development environment. So even if you don't make that your career, or there's a good chance you won't, you should still know enough to say hello to the large number of people who are making it the career and also to know not to make stupid mistakes while you're designing your software. All right, so I'm trying to give you a pep talk to convince you this stuff is important. How many people think security is unimportant? Ha! All right, everybody likes to give lip service to it, but a lot of us like to skip over it anyway. All right, let's try not to be that person. Okay, so let's give it a shot. What do you need to sort of do this, right? What's step one? In fact, maybe I should make this step zero. We're computer scientists, right? we start counting from zero. What's step zero? Step zero is you need two things to sort of start off, to even think about security, right? First, a security model. I'm not talking about code. I'm talking about something in your head or something quite possibly that you'll write down in which you model what you're defending. This is a model of your application and what it needs to defend. Security is about defense. The black hats are on offense. You're the defender. And if you don't know what you're defending, you'll waste a lot of time. You may think you're doing security, but you'll be defending the wrong thing. One of the first things you'll learn about playing defense in security is there's always more to do. There's never perfect security. You can always spend more money making your application more secure, which means you have to prioritize, which means you have to leave some things undefended. Which means they had better be the other unimportant things you won't know which things are important or not Unless you have a security model So you should have a security model of what your application is depending the assets and all that sort of thing And you can probably guess now What the other major thing you need is? Right. Here's what you're defending You also need a threat model This is a model of what the attacks will look like, right? That is, who's attacking your application and how they're going to attack. Again, if this model is inaccurate, you're going to waste your time worrying about attacks that are so unlikely in practice, they're never going to happen, you'll waste money in defense, right? You want both of these models to be accurate. They should be good models. What you'll find is that the models are never perfect. You can always make your models better, just as you can always make your software better, but you have to come up with reasonably good models, if you fail in step zero, there's a good chance you're going to fail in the long run in building your applications. So I hope that as part of your course project, that fun thing you've been doing in your group, right, where you're supposed to be thinking about security, remember that was one of the lines in the project? You have those in your head and also at least briefly written down so that other people who either develop or use your application will know what your security model is and what your threat model is any questions about this big topic all right well Let's take a look at a security model. So this is sort of what you mean by security in your application. Now applications will differ. Some people will think some things are more important. You know, you can be all over the map here. But the classic sort of components of a typical security model are what are commonly called the CIA triad. What a clever acronym, right? It's not short for Central Intelligence Agency. It's short for something else. Confidentiality. This is sometimes called privacy. And the basic idea of confidentiality is pretty simple. Here is your application, right? Inside the application is a bunch of information. Confidentiality says this information does not leak out. It keeps confidential stuff in the system and doesn't let the attacker see that confidential information. So, for example, your grades are confidential. They're stored in a server somewhere in Murphy Hall, but they're pretty good about security there and they won't let it leak out to people who aren't authorized to know what the grades are. Second one is integrity. This is just the opposite. The second one is integrity. The of confidentiality. Integrity means the bad guys can't go and stomp on the information. Right? You can't have someone, say, from USC go into the registrar and start giving everybody at UCLA an F. Right? That would be a violation of integrity. Sometimes integrity is called, you know, sort of tamper prevention, shall we say. The third one, A, is availability. Availability is, is the system up at all? Can you use it at all. This is sometimes called service. And if I were to try to draw a picture of it, it would be sort of like, look like this. The whole system is down due to the network being out or the power being out or some bug in your system or whatever. You haven't lost Data is not leaking out, it's not leaking in, but you can't use the application at all. And that can be a security problem just as much as the other guys. Any questions on these three security aspects? Yes? Is this supposed to be a service? Oh yes, service. Thank you. Right. Service, thank you. All right. So, what you need to do is keep these three things in mind when You're coming up with a security model for your particular application. All right. So, what you needs to identify in Your security model, To some extent every application should have its own security model because every application is different There's a lot of things you need to identify but three things I suggest doing is first what are your assets? What are the crown jewels of your application? What's the information that the bad guys want to attack? Either by reading it or by writing it if you don't know what your assets are Then you're gonna have a tough time figuring out how to defend them Oftentimes people forget some of their assets They'll think the asset is everything in the database say right and then if it's not a database. It's not part of the assets No That won't necessarily be all the assets For example the contents of your configuration files are normally considered to be part of the assets of your application even though they're not in a database, they're just some sort of startup file. You need to be careful about identifying them, don't, you know, don't miss. It's probably better to be a little generous and put stuff in here, even if it's not important, than to forget stuff. Second thing you need to identify are vulnerabilities. These are channels of attack by which one of the black hats can attack your assets. So there are ways into the system that you don't want to allow. There are ways out of the system that you don't want to allow. Or there are ways that the attacker can bring the system down. An attack on either C or I or A. Third thing you need to identify are threats. The difference between a vulnerability and a threat is a vulnerability is a channel into your system. It's a weakness in your system. A threat is a bad actor out there that quite possibly is going to attack your system via its vulnerability. You need to be able to identify both. To some extent here, you're looking at your system, right? To identify threats, you need to look at the environment. The environment that the system will run in. Okay, so you have to look in and you have to look out. All right. Any questions about this? To some extent, I'm sort of, I hope, preaching to the choir here. I'm telling you stuff that you would look at this and say, yes, yes, yes, I agree with all this, right? Maybe I didn't know each of these fancy technical words all before, but all this is obvious things to do. You'd be surprised at how many real world projects forget to do something on this blackboard even though it's all essential. Don't forget. Make sure you get all of this stuff done. All right. So once you have a security model, well, there's actually one thing else that you need in your security model, right? So here is sort of what you're protecting. Here is sort of what the bad guys will do. You also need to know what will the good guys do in order to sort of defend this stuff. So under that, there are several sort of general functions needed. And by functions, I mean functions of your application for, you know, almost any security Not every application needs to worry about all these functions, but it's good to have to have trying to verify that someone who pretends to be Dr. Eggert really is the authentic Dr. Eggert and not some fake Dr. Eggert. So here, obviously, you could go off the deep end, right? How do you know I'm really me and not an actor pretending to be me? I'm not talking about anything like that. I'm talking about sort of run-of-the-mill authentication. How do you know someone using your system is, you know, the user they pretend to be? A classic example of authentication, of course, is passwords. It's been used for decades, and I assume you know some of the problems with passwords. Like UCLA won't even let you connect to Bruin Learn just with a password. But it's a standard technique. What do you need to do to connect to Bruin Learn? We have multi-factor authentication. For Brew and Learn, it's two-factor authentication. So you need a password and something else. When I just arranged to have this lecture recorded on Gradescope, I had to authenticate myself. And you saw me do my password. I hope you weren't recording that. But then I had to pull out this duo key, which has a six-digit number that changes every few minutes. And I have to put whatever it's saying right now onto the screen, won't let me log in, right? That's two-factor authentication. Anybody here use this kind of authentication? All right. So what do you guys use if you're not using this? An app. So you trust Duo's app on your cell phone? Man, I don't do that. No, seriously. Why would I do that? Right? I mean, that's, that's, right? And, but, you know, you have to be careful about this sort of thing. This thing has a battery in it, right? Suppose the battery goes dead, which it does about once a year. Battery expires, right? Then all of a sudden I can't log in, except I have a USB key as well as a backup, right? So I really have three-factor authentication Since UCLA is only requiring two, I can manage to log in, I hope. All right. So this sort of thing means you can have two, in some cases more. So you can have, you know, USB keys. You can have other devices. If you want to go into certain labs in the medical center, the way you do it is you walk up to the door and you look into an optical scanner and they scan your eyeball to make sure you're you. That sort of thing, right? So there's lots of sort of approaches to doing this sort of thing. Biometrics is an approach. None of these approaches are perfect. For example, they used to use fingerprint scanners in the med center, but a problem with fingerprint scanners is all I have to do is give you a glass of water to drink. When you give it back to me, I have your fingerprint. and then I can put a thin layer of gelatin on my thumb and imprint your thumbprint on my thumb and then go connect and log in and remove all the evidence. So you have to be careful about any of these schemes. None of them is perfect, which is why multi-factor authentication is considered to be better than any single method of authentication. Any questions about authentication? Yes? . All MFA means is you require several properties of a person in order to authenticate them, right? So those properties could be something the person knows, like a password. It could be something the person has, like one of these USB things, right? Or it could be something that the person is, like your eyeballs' contents, right? And all MFA means is take at least two of those things, right? It doesn't necessarily imply a hashing algorithm or anything like that. Anything else? Other questions about authentication? Yes? Oh. Well, here, yes, we're going a little bit into the deep. But all right, so there is a password and then a passphrase, which is the version I've heard, and I'm not sure about a passkey. But a passphrase is going to be a password that lets you go in and get your file that contains your real passwords or your real keys. So it's a it's sort of a key and inside the safe is a bunch of other keys and That kind of approach is often used in authentication I'm louder, please I'm still not hearing sorry is it I mean I have a bunch of Air conditioning noise on my end of this Is that how they do it so you can log into other sites using the package? Yes. So Apple and Google and other people will arrange to keep track of your passwords for you in a safe vault. And then you have to authenticate yourself to them so that they can then turn around and use those passwords. There's a lot of complicated machinery here behind authentication. All right? But you need to do it one way or another. All right? Second thing you need is authorization. Authentication just proves that the user is Dr. Eggert. Authorization says, here's what Dr. Eggert is allowed to do. So as far as UCLA systems are concerned, I'm allowed to set student grades in my classes, but I'm not allowed, I'm not authorized to change the grades of a student in any class that I didn't teach, right? That would be ridiculous. I could go change your grade in any class, right? I'm not authorized to do that. I'm not authorized to change my salary, right? So there's a lot of authorization rules that are present at UCLA or in any real system, and you're going to have to keep track of how this works. An example of authorization in computerish would be access control lists. An access control list works as follows: you have a resource you're worried about, say a file on c-snaps. associated with this resource is a list of users and what they're allowed to do with this resource. That sort of thing, right? So here are three users, Egert, Milstein, and Frank, and Egert can read, write, and execute this resource. Milstein can only read And Frank, oh, well, let's not give Frank all that capability. All right? Now, notice that ACLs are more general than the security model you're used to on CSNAT. Remember I showed you RWX for user group and other towards the start of the course? This means you can grant individual control for any set of users that you like, which is much more powerful than the standard sort of security model. CSNAT supports this, it's just we didn't tell you about it. But this is a standard sort of authorization technique that you might want to use. Next function that you need is an integrity function. And to some extent, that's a duplication from this. And to some extent here, what we're doing is we're focusing on mechanisms to ensure integrity in the system. Here, the basic idea is as follows: no matter how secure you make the system, right, we have authentication and authorization and all that sort of thing, very careful about that, there will always be breakdowns somewhere, right? Someone will shoulder surf my password at LAX. That's a standard technique, right? People just have video cameras. If you type your password into a laptop or a cell phone in LAX, you're nuts, right? And then, you know, the password leaks out. If you only had single factor authentication, right, they'll break into the system. Integrity is what you do then, right? In some sense, what you're trying to do here is detect when someone has broken into the system has successfully launched an integrity attack, has modified information that they shouldn't have, what do you do then? Some standard techniques or functions in this category include checksums. For each resource that's important, you take a checksum of that resource, you put that checksum in a very, very secure place compared to where you put everything else, and periodically you make sure that the check sums match. If they don't match, somebody's broken in. Another obvious thing that you can do for integrity is do backups. If you do backups properly, and if the attacker can't go and attack your backups, then at worst you will have lost a day's worth of work or however long it is between backups. All right? Next sort of thing you can do, general function, is going to be auditing. Here the idea is, okay, the horse has left the barn. Let's at least record the fact that the horse left the barn so that we know when our system stopped being secure. right so a standard technique and auditing are logs you log everything that everybody does and if someone has broken into the system and has done something bad at least the log will tell you when they started doing it and then you know which backup to start working from from there There are other things that you typically want in a security system, but these are probably the top four, except, well, I sort of left a couple things out that we often take for granted. So let me put them down here. Last on the list, not necessarily least. First off, we don't want any of the security functions in your application to break the application. That is, we need to keep our application correct. It still needs to do the function that we're trying to build in the first place. If the security makes the application not do that, then there's something wrong with the security. Another thing that we always have to keep around in the back of our mind or sometimes in the front of our mind is efficiency. Whatever security features we have can't be so onerous, either on the system or on the humans, that they can't get their work done. If the system is spending 99% of its time doing security stuff and only 1% of the time doing actual work, well, that is probably not a good thing. And we're talking about efficiency here both for the human users and for the software and hardware that you're using to run the system. The standard joke about correctness is that here's the most secure computer system in the world. This is a scotch tape dispenser, right? Because it's a brick, right? Bricks are really safe. It'll never leak any information. It's tamper-proof in the sense that you can't tamper any information in it, right? So it satisfies all of this stuff except for this last little bit down here. It's not correct. It doesn't do anything. It doesn't do what you want to do. So don't forget about correctness. All right. So we've got security models, what you need to identify, general functions you need to do, and let's now talk about this. Until now, I've been mostly focusing on security model. I've talked a little bit about threats and all that sort of thing. Now I want to talk about threat models and kind of what they look like. When you're doing threat modeling, what you'll discover is like any sort of tinfoil hat exercise, there's going to be a ton of threats out there. There are like, how many billion people in the world? Eight billion, is it now? And they're all out to get you. Well, not really, but you can list a whole bunch of models. So, at part of your sort of threat modeling can't just be listing more and more and more things to worry about. You also have to do classification of these threat models. This classification is done for a couple reasons. First, you need to establish priorities. Some of the threats are going to be more realistic than others. Some of the threats are going to be more dangerous if they happen than others. And the classification is going to help you sort of prioritize and that sort of thing. The other reason you need to classify is you will know how your application is built. You will know the functions that you're using in order to defend it. And you can also classify the threats according to how you plan to defend against those threats. So there's a couple of reasons here why you might want to classify them. That being said, here's a quick sketch of some threats or classes of threats that you might want to consider for your system. The first one is network attacks. And by that I assume your application is running on the internet or some network like the internet. And you have to worry about all the bad guys, all the bad actors on the internet that are trying to break into your system. And I hope you are familiar with some of the phrases I'm about to give you because there's a whole bunch of network attacks. These are perhaps the most popular ones, at least if you see what is published in the newspapers and that sort of thing. First one is phishing. A few years ago, a security analyst working for the University of California Office of the President up in Oakland-- so this is like my boss's boss's boss's boss's boss's secretary-- clicked on email that had a bad link in it. The attacker broke into the Microsoft Windows machine that this assistant was using, used it to attack further machines on the highly secure network running in the office of the president of the University of California and basically stole everybody's information, right? So that was a phishing attack, right? It was email directed at someone that they knew this person was highly placed at the University of California. They were trying to find a well-known bug in Microsoft Windows that they hadn't updated their Windows machine for a while, right? And they successfully used it. How many people here have been victims of phishing attacks? I see two people raising their hand. All right. Yes, it does happen. Often it happens and you don't know that it happened. But when you do know that it happens, it can be quite painful, right? Be very careful about that. One way that I use to defend myself against phishing attacks is I configure my email client to only show text versions of email. I never see images or anything looking like an HTML or a web page when I'm reading my email. I just see text. It's very boring. But also, it makes it very obvious where the links are and what will happen if I press on it because there's only text on the screen. I highly recommend this. In fact, I recommend this to everybody working for the office of the president of the University of California. If they had been using the same email client that I'm using, my paycheck would not have been leaked to the public. All right. The next one is drive-by downloads. In some sense, this is a variant of a phishing attack. This is a website that has something nice and tempting. Just press on this and, for example, it'll give you an image of something. The image uses WebP, which is a nice new image compression algorithm, but the WebP image is corrupted internally. Internally, it specifies RGB values that are impossible or vector sizes that are impossible. It exploits a bug in Safari. The bug in Safari causes Safari to leak out your mother's maiden name to the attacker or whatever, right? So that's a drive-by download. And in some sense, it's just like phishing, except it's via the web rather than via email. You can probably guess other variants that are like this, right? The basic idea is fool the victim into launching an attack on their browser or their email client or whatever. Next form of network attack is denial of service. So popular that it has a nice little acronym, denial of service, right? So this is an attack on availability, and the basic idea is the attacker launches a whole bunch of requests on your poor little web browser until it gets overloaded and it can't get anything done. Even normal users can't get anything done. This is commonly done by the attacker finding a bunch of clueless people on the internet, attacking their instances of Windows or Mac OS or whatever, turning their machines into little attack bots, and then launching a swarm of attack bots on your web server. They can have thousands of users all of a sudden appear and start going and attacking your web server. By the way, how would you defend against this? Any thoughts? Yes? If you put limits on how often requests are made or where they're coming from, things like that, you can kind of try to make sure that the people using your app are actual users and not. Right, so you throttle requests, right? The server just refuses to take more than, say, a thousand requests per second or whatever capacity it can normally do, right? So that's one way to do it, and that means that anyone who actually gets a request into the system is going to get an answer back. Obviously, though, it's not enough, right? Because what it means is that the attackers now sort of crowd out the users. The users can get some work done if they can get in, but a lot of them can't get in. So you need to have something better when you're dealing with a major denial of service attack. And that's beyond the scope of this class, thank goodness. All right, next one, buffer overruns. Under this approach, the attacker gets a copy of the source code to your application, which is written in a terrible language like C or C++. And because your application was written by fallible humans, perhaps assisted by even worse chatbots, your application has some bugs in it that can cause it to have a subscript error. That subscript error can overrun a buffer. The buffer is sitting on the stack. Because your application has a bug, it overwrites stuff that it shouldn't. And then really bad things happen. How bad? Well, here's main's frame. Main calls F. F declares a buffer sitting in here. F is buggy. It has a buffer overrun bug that the attacker exploits. The attacker sends a carefully coded message to your application, causing F's bug to trigger. It scribbles on the buffer, which is okay because that's just input data, but it keeps scribbling until it gets to right here. This is the return address. That's where control will go to when F returns. This means the attacker now has control over what code your program will execute once F returns. You are toast. How do you defend against this? I hope you remember my lecture from like two weeks ago, right? That's one way. There's lots of other ways where this came from. To some extent, this is almost a solved problem now, except it keeps coming up every now and It hasn't gone away. There's too much stuff written out there in low-level languages where people wanted to run fast and didn't necessarily want to run safe. All right. Cross-site scripting. Under this approach, the attacker convinces your browser to run JavaScript, which is not a big deal these days. Everybody has JavaScript in their websites, right? But what the JavaScript code that the attacker convinces your browser to run does is go visit your bank and, you know, transfer some money from your bank account to the attacker's bank account, right? Because JavaScript code, it's code. It can do anything. It can sort of say, "Oh, you have a session open to your bank. Oh, let's go withdraw some money." That's the whole convenience of JavaScript is that it's code, right? This is a very serious form of attack. I might have more to say about it later, but it's definitely something that you need to worry about. Another one, prototype pollution. This has to do with how JavaScript is implemented. JavaScript is a prototype-based language. The way you create an object is you clone another object, which is the prototype. Your object inherits all the properties of the thing that it was cloned from. If the attacker can attack the prototype, all of a sudden it has control over all of your objects, or at least partial control. JavaScript people love to do this, right? They'll try to write bad JavaScript code that will go find a bug in your JavaScript code that will pollute a prototype and then take over your JavaScript application. I mean, this is, I've probably said too much about network attacks. I hope you realize this is like a big deal. It's not the only deal. There are other attacks, lower level attacks, device attacks. Classic example of a device attack is a bad USB stick. you plug the USB stick into your computer, you lose power to the computer for whatever reason, the computer reboots, it decides to boot off the USB stick rather than from your internal flash drive because that's the order that's sitting there in the boot sequence for your computer. The bad guy now has complete control over your computer, right, because it's running early in the boot sequence before the operating system even takes control. This happened to U.S. forces in Afghanistan back when they were in that country. The soldiers ran short of USB sticks. They went to the market in Kabul and bought a bunch of them and took them back to the base and plugged them in. You gotta be kidding me. It was my reaction, Right, but that's a real problem. Okay. Any other device attacks you'd like to hear about? There's lots more where this came from. All right. I've sort of talked about the stuff that, you know, in some sense you can think of this as being network, you can think of this as being hardware and that sort of thing. But there are two forms of attacks that really aren't technical, but you should know about them because you'll run into them in any major software application. The first one is social engineering. The most famous hacker in Southern California history, a fellow by the name of Kevin Mitnick, was not much of a software guy at all. What he was really good at was social engineering. So in one of his attacks, what he would do is he would wear a yellow safety vest, and he would dress up like a telephone repairman, and he would climb the telephone pole next to one of his victim's offices and put clamps on the wires and then call the office and say, I'm fixing the lines into your system because the telephone lines have gone bad, right? Can you give me access to your telephone system so that I can verify that it's all working now? Now, of course, in hindsight, nobody should fall for something like that. You shouldn't trust some random person up on a telephone pole to be an actual telephone repair person. But lots of people fell for it, and he could break into systems left and right simply by social engineering. Another option would be you go to Kirchhoff Hall and you say, I'm Professor Eggert and I lost my card. Can you give me a card? And as long as you've got a beard that kind of looks like this, right? I mean, they're going to trust you, right? I mean, they're going to ask for ID, but you've lost your ID, right? So social engineering is a real problem. In some sense, a harder problem to defend against, but one that is all too common, is insiders. These are people that have been authorized. They have been authenticated. They've satisfied all the stuff that we've talked about here, and yet they go in and do bad things with the system. Ideally, you'd like a system that's robust even there. And for that sort of thing, you'd better have good integrity and good auditing, right? Because these two approaches are not going to save you from insider attacks. All right. Any questions about all these mechanisms? So in some sense, I kind of feel like I'm being a little bit of a cheerleader here. You know, all this stuff is important. It's obviously important, all that sort of thing. I just want to get a little feedback. Is all this stuff so obvious that you knew about it already? Right? Because since I'm not getting a lot of questions, I think maybe I should speed up the second half of my lecture because I'm going too slowly, right? How many people want me to go faster in the second half of the lecture? I always want to go faster. How many people want me to go slower? All right, a little bit slower. All right, let's take a break, and I'll try to go a little bit slower for our second half. All right, let's start up again. So I'd like to do a little bit something practical here, because I feel like the first half of my lecture I was just talking theory. And so what I did was I went to the Open Worldwide Application Security Project, which you can look up under this acronym, right? Open Worldwide Application Security Project. The W used to stand for web, but now they feel like they've generalized beyond that. Every four years, they come up with a list of the top application security threats on the web or on the internet, whichever way you want to look at it. The last time they did this was almost exactly four years ago. So I'm going to give you their opinion four years ago of what the top threats are. They're coming up with a new list. It should be available this fall. So the next time I teach this class, I'll teach a new list. But, you know, this is the best that we have now. So this is their top 10 list of security threats in 2021. This isn't to say it'll be the top 10 threats against your application, but the implication here is that you should know about these common sorts of mistakes so that you don't make them yourself. Number one is broken access control. Remember, I was talking about ACLs, access control lists. That's part of authorization. So what they're really talking about here is your authorization is busted. You've authorized the wrong people to have access. Here are some examples of this number one security threats. First off, you have sort of the ability to modify a URL. What do I mean by that? I mean that your application, you know, people click and they visit different parts of your application. Each part of that application has a URL. what the bad guys will do is it'll look at those URLs that you would get normally, and then go and edit the URLs directly, and go visit other parts of your application that you didn't think they could get to. But they can get to it. All they have to do is edit the URL, right? And they're off to the races. Similarly, if you have, say, a JSON web token, Sometimes called a JWT. This is a bit of JSON that your application can sort of pass around to it. It gets authorization to visit a website. When it needs to go and do something at the website, it presents the web token to the website saying, yes, I'm authorized. Here's the proof. Well, they can look at those JWTs and edit them because they're sent to your browser. Your browser knows what the JWT is. All they need is a browser that records the JWTs, and then they can go edit them and try them out and attack your system that way. All right. Similarly for cookies. Right. So basically modifying anything, any information that comes from the web server back to the browser, they'll edit it before they send it back to you and then break into your system. Another example of this is providing a unique ID. So the technical term here is an insecure direct object reference. Oh, shoot. Too often you'll see, say, URLs with long strings of decimal or hexadecimal digits in them. Those are IDs of some internal part of the system. What the attackers will do is it'll take those ideas and infer properties of your application or reuse the IDs in some other command. In some sense, this is related to the first thing, but in some sense, this is different because what they're really after is they're really after these IDs. You don't want to be disclosing them to the web clients if you can avoid it. If you do, you're sort of running the risk of having bad access control like this. Number two, this is roughly in descending order of popularity, shall we say. is crypto failures. Examples of this include using HTTP instead of using HTTPS. People using an insecure channel to talk between the client and the server. The bad guys are in charge of the routers in between and can insert corrupted data back from the server back to the client that sort of thing another one is using weak crypto algorithms designing good crypto algorithms is to some extent an art not a science as the years go on We've gotten better at designing crypto algorithms. We've also gotten better at attacking the old crypto algorithms. It's tempting to keep using the same crypto algorithm that your grandparents used. But if you do, there's a good chance someone can crack them. So that's a problem that you'll run into. Another one is not validating certificates. certificates. When you visit https:www.microsoft.com or www.ucla.edu, the way that you know you're actually talking to Microsoft or to UCLA and not to someone masquerading as the place you're talking to is via a technique called certificates. Built into your browser is a set of cryptographically secure certificates of certificate authorities. There's maybe, I don't know, a few dozen of those. These certificate authorities will hand out further certificates to places like UCLA and Microsoft. Your application can validate that it's talking actually to Microsoft, but But a lot of people don't bother because it's a hassle. Or they do it and they do it incorrectly. So make sure you validate certificates when you are visiting third party websites and similar sorts of applications because there's too many people out there trying to masquerade. Third problem is injection. An injection attack basically occurs when your application trusts the user to give it properly formed data. So don't do that. Classic example of that might be something like this, right? The website says hey, what's your name? And I say my name is Double quote From no drop table I don't know, what's the worst table you can drop? Payroll or something, right? And then double quote, something like that, right? And what your naive application does is it takes this string, plops it into an SQL request. The SQL request started to say, you know, select name from blah, blah, blah. you've turned it into an SQL request that destroys the application's database, right? Drops the main table, payroll table. Obviously, this can do something other than drop. The point is you've broken into the system by giving it poorly formed data. That's not a valid name, but you picked that poorly formed data because you know the application didn't properly quote the data and thus is victim to this kind of attack. This is why so many websites say, "Please pick a password, but do not use these characters in your password." There's a small set of other characters. You know why it's picking those small set of characters. They look like they could be HTML or SQL, you know, special characters, and thus could screw up their internal application. And they don't trust the quoting on their internal application, so they simply ban these characters from all of your passwords. Any questions on injection attacks? Yes? Sorry, this is actually going back to broken access. JOHN MCCUTCHAN: Oh, yes. But how can we prevent a user from ending JWT with that? JOHN MCCUTCHAN: You can't. OK. JOHN MCCUTCHAN: Right, so you basically don't trust it. You can use JWT for advice, maybe, performance things or that sort of thing. But trying to use it for authentication, anything important, I wouldn't. Again, the opinion's different. If this is just some sort of fun game application, security is not that big a deal. But if it's in charge of my paycheck, please don't use this sort of thing. Other questions? Yes. I thought regarding JWT, you could sign in for private key and then check if it's in temper. Oh, yes. That is, you can, in some sense, you can verify the JWT later, right? And so if someone has edited it, and if you can detect the fact that they've edited it, and then, if you're that careful about it, then that approach can work. Yes, absolutely. Yes? For the skill injection, do you have to know if you should pay the cost for it? Well, the easiest attack is one where you exactly know what the application is and what the scheme is and all that sort of thing. However, if you know that they're kind of buggy, you can start issuing requests like this and see what happens and then tune it. You can sort of explore the database. This can be something that says, oh, please tell me your schema. And then you get a copy of the schema and then you're off to the races. All right. other comments about these attacks. Alright, let's do another one. Number four. Oh, I don't like number four, but I'll mention it. Insecure design, which means not following good practices overall. In some sense that's kind of a vague thing, well you have a design scope. In some sense what it means is they didn't listen to the first half of this lecture, right? They didn't do threat modeling. They didn't do all the other stuff that we talked about. And so they came up with something that was, you know, totally secure for the wrong set of threats. Next one is security misconfiguration. Classic examples include you buy a router from Best Buy, and you have root access to the router because the root's name is admin and the password is password, right? Lots of people set up their routers and they don't change the root password, which means now anyone who can, you know, have access to that router can go and fiddle with the router and do whatever they like, right? So that's a very common configuration problem. Another problem is there will be maintenance ports left open. You're configuring a web server on some Apache instance of that sort of thing. It comes on AWS, I meant to say, and it comes from, you know, with sort of the maintenance ports, which you use to log in and set up the web server and all that sort of thing. But you left those maintenance ports open. So now anybody can log into the web server and start looking at the configuration and changing it and that sort of thing. All right. This sort of thing happens a lot. A lot of the sort of break-ins and, I don't know, leaking of corporate government data are just maintenance ports left open in, you know, box, that sort of thing. Number six, vulnerable and outdated components. The phishing attack that I mentioned on the University of California Office of the President wasn't simply phishing. It was also based on method six. What they did is they took over control of a Windows client sitting inside this trusted network and then they used that to attack an old sort of vault repository server. It was intended to be a secure storage for sensitive data held by the university. And what the university had decided to do was not pay for software support for this old server, it was still running Linux 2. something, which is an ancient version of Linux with known security holes, and the attacker said, "Oh, let's go break into this system." That's vulnerability number six. Don't be that person. Don't run an old version of Chrome. You gotta be kidding me. The bad guys know about all of its bugs. Second, seven, I should say, ID and authentication failures. For example, if your application lets users log in by name and password, can an attacker write a script that just keeps guessing passwords, right? This kind of attack was one of the main reasons that UCLA went to multi-factor authentication a few years ago. Too many students had their password being 1234 or something like that, right? And the password guessers were going to town, breaking into various UCLA sites, right? In some sense, the two-factor authentication helps to defend against this kind of bad design of passwords. Also you don't want to allow easy passwords. Does your project allow people to use the password 1234? It shouldn't, right? Problem number seven, right? You thought you had a secure application, I bet, right? Number eight, software and data integrity failure. So here are a couple of examples of this kind of failure. You have bad access control to your developer's site. Say GitHub. You let the guy you met at the coffee shop log in to you as you on GitHub. That sort of thing. Or more generally, not checking the integrity of your software supply chain. If you log in to CSnet and run the command sort, how do you know that that command is actually GNU sort and not some bad person sort that occasionally will leak out information to whatever, right? There are ways in which we detect, you know, people tampering software and that sort of thing, right? But you also have to make sure that you got sort from a reliable source, right? You didn't just pick up a copy of sort off the net. You got it directly from Red Hat or from Ubuntu or directly from the GNU project, something like that, right? A lot of times people feel like they don't have the time for this. They just grab stuff off the net and use it. They just use pip install. Oh, good. It's installed now. I'm happy. Well, where did you get that stuff from? And how do you know it wasn't tampered in the meantime? This thing is actually becoming a bigger and bigger problem because attacks on the supply chain are becoming more popular than they were even back in 2021. I'm constantly being bombarded by email, by people trying to, you know, verify that software that I wrote was really written by me, that sort of thing. And I expect this to actually become more important in the future. We got two more. Security logging. and monitoring failures. I mentioned logs as being one of the basic techniques that you use to sort of watch out for people attacking your system and also recovering when they do manage to get in. A logging failure means that you didn't do the logs. You forgot to turn on the logger, Or you turned it on and it filled up the log and then stopped working after that. That's a logging failure. A monitoring failure occurs when you have the logs but nobody's looking at them. So you logged everything, the guy broke into the system, nobody paid attention. You don't want to have either kind of failure, at least on any system where high reliability is needed. Okay, number 10 is one that has its own acronym, server-side request forgery, or SSRF. So the idea here, in some sense, is a combination of some of the earlier ideas. But what happens here is the client tricks the web server, or it doesn't have to be a web server. It can be any kind of server, right? To use a URL that's valid only inside the server's secure network. So oftentimes applications are built this way. Here's the Internet, full of bad guys. Over here we have a firewall. And inside the firewall we have a web server that's somewhat protected from the Internet because there's this level of protection in between. Even the web server, though, is talking to another network back here. Back here is our database server. The database server is now two hops away from the Internet. It's really protected really strongly from any attacks on the Internet. They first have to get through the firewall. Then they have to get through the web server. Nobody's going to be able to do that. Right? Wrong. What happens is the client here, the bad client, constructs a URL that might look like this, httpvictim.com, and then it's some long string in here, and somewhere in this string is http 192.54.239.12 and some other stuff. The web server takes this long URL, says, oh, this is part of a request that I'm using inside my own internal network. Here's the database server, 192.54. This is a private network. You can't get at this from the outside world. But the web server can because the web server is connected to the internal network. It has to be in order to sort of operate. So the client is tricking the web server to access stuff that the client wants to see as opposed to accessing stuff that the web server would ordinarily want to see. All right. Well, I don't claim this list is comprehensive. And to some extent, the list is a little bit obsolete already. But this should give you a feeling for a lot of the things that can go wrong in real sort of network or web-ish applications. And you should be familiar with this sort of thing because you're gonna be running into it when you build stuff like this out in the real world. All right, any questions? Yes. The which one? Oh, well, I just mean that you grant access to people that you shouldn't, right? You had five people in your project. One person dropped out. Unbeknownst to you, that person started working for USC. And they're now trying to make UCLA look bad. You forgot to remove them from the list of people that have commit rights to your repository, right? So that's a classic example of bad access control. Yes? You were saying you had people asking you if you actually wrote written software. Yeah, and how do I do that, right? Or how often has it been that it's faulty when they ask you? It's not actually software you've got. People don't like to admit being broken into. So I don't really know. The only times that I can recall people asking, it was really me. But to some extent, that's sort of expected. The sort of person who's likely to double-check the software supply chain is also the sort of person who probably got the right version in the first place, right? So they're just double-checking. But, you know, this sort of thing is, you know, there's like executive orders coming from the Biden administration and now the Trump administration to do better job in this, right? And it's turning, to some extent, you know, from a skeptical point of view, it's turning into a lot of paperwork. There's a lot of people sort of doing all this supply chain integrity checking and then you wonder, you know, maybe they would have, you know, better luck improving security by turning their attention elsewhere. You can do too much of this, I guess what I'm trying to say. All right. So let's talk about testing. And in a real sense, testing security is different. All right. Ordinarily, if you're just writing code for CS31 or for this class and all that sort of thing, you'll make mistakes. Your code will contain bugs. You should have some test cases to sort of, you know, do a sanity check on your code doing a reasonable thing. But it's safe to say that those, you know, the kinds of tests that you write are the kinds of, it sort of uses test cases, sort of what you think users will do. So you will try to provide test cases that cover ordinary usage, right? When you're testing security, though, in some sense, it's quite a different feel, right? Because ordinarily, right, failures are, how shall I say it, random. I'll put random in quotes, right? That is, you'll have some bugs in your program. A lot of times when you run, the bugs won't trigger. Sometimes you'll get unlucky and the input will actually trigger the bug and then you have to go fix it, right? But that's just, you know, the way the world works. It's like driving a car down the road. Occasionally you have to watch out. There'll be a pothole and that sort of thing. When you're testing security, though, you have to assume that the failures are not random. You have to assume that you're running a program in an environment where the world is out to get you. You're driving down the street and the potholes will suddenly appear right where your wheels are, right? Because the street is out to get you. It's not just random failures on the street. It's designed by the attackers to make your programs fail, right? So security testing has to operate in an environment, right? The bad guys are out to get you. And for that reason, you can't have as your inputs to your program when you're doing security testing sort of the likely inputs that users will give you because the bad guys are not ordinary users. They're like devilish attackers, right? If there's some part of your code that's only executed once every billion applications but it has a bug, they will go be that billionth guy, right? So you're going to have to sort of think about how to do testing in a way that works in this, basically, it's a much harder environment to test. All right, so what advice can I give you? Well, first off, I'll say number one, static analysis is your friend. In static analysis, the compiler or auxiliary program looks at your program and sees if there's any possible way that a bug can occur. And if there is any possible way, it yells at you, which means that if you pass a static analysis test, you know the bug can't occur no matter what the bad guys do. That's a huge win. And for this reason, people that are serious about security are big on using systems where static analysis can really make a difference. thing, I'll make this number two, is you have to think like a bad guy when you're testing this system. And to some extent, there are specialists in this area, right? They're black hats for hire, you might think. So you can do what's called penetration testing. There's another thing about security. So security often involves multiple levels of distraction. Or another way of thinking about it is attacks often involve involve sort of breaking abstraction boundaries. So let me give a simple example. This one is in some sense contrived. You won't see this fault in any real-world system these days, but it'll give you a feel for how you can break abstraction boundaries to break into a system. Suppose we have the following sort of API, and the API is sort of check password, And it takes, you know, two arguments, the name and the password. Right? Each of these is, I'll just use C terminology of type char star. Right? So they're both character strings. And you call that function. And it goes and looks up the name in its secret database. It looks up the password in its secret database. It doesn't show you what the password is and all that sort of thing. but it returns true if it's the correct password and false otherwise. And suppose you look at the implementation of check password. And the implementation sort of looks like this, right? Look up name. And, you know, P gets that. And then we do if you compare the strings of P arrow PWD to password equals equal zero, right? You return true. In fact, I can just say return this, right? So it's pretty simple. It looks up the password in the database, does a string compare, returns true if the password's right, and false otherwise. And suppose this implementation here is behind a lockbox. You're not allowed to go run lookup yourself. You can't look inside the database. You don't know where the password's all at and all that sort of thing. All you have is this API. And what you would like to do is log in as root. Okay? There is an easy way to do it. that involves the way that string compare works. How does string compare work? Look inside string compare, and you'll see code that looks something like this. Right? While star n and n star n plus plus equals star p plus plus. Continue. All right, so it looks for the correct password, compares it to the passwords that's applied, and at the end, it can return a value that if you ran to the end of the string, it'll return success, otherwise it'll return failure. You can't change this. This code is kept under lock and key, but you know what the code looks like. So here's what you do. You arrange to put the password at just before the start of a page boundary. Each page is, say, 8 kibby bytes. So here's 8 kibby bytes, here's 8 kibby bytes. You put the password that you're guessing so that the first byte of the guest password is on one page. We'll call this page A. The second byte is on page B. You arrange for this page to be in RAM. You can use this with system calls like MMAP. You can do a man-MMAP system call or take the operating system course to know what that means. But basically the idea is this thing is in RAM. This thing is out on Flash somewhere. It'll be brought into RAM if necessary, but that will be slow. Now, what you do is you guess, does the password start with A, just lowercase A, right? You run this, you see how long it took to get the answer no, right? If the answer no came back right away, that meant that A is wrong, right? Because it found out right away. It never had to read page BN. This takes a long time. If the answer comes back no, but it takes a while, that means your A is right. There's only 256 possible first bytes in the password. So all you have to do is make 256 guesses. Afterwards, you will know what is the first byte of the password. Then you repeat. Except this time, you move the boundary over a little bit. If it turns out that Q is the correct thing, now you start guessing the second character. So if the password is, say, 10 bytes, ordinarily it would take 256 to the 10th guesses. But under this approach, you only have to make 10 times 256 guesses, worst case. you've greatly decreased the cost of password guessing by violating the abstraction value. Now, this kind of approach is unfortunately all too often used even in modern web browsers and modern applications. And what happens is we can use sort of bad addresses. I'll put bad in quotes. To infer contents of sort of victim applications. and the basic idea is i'll give you a simple version of it is let's find a bug somewhere in your program where your program will you know have a memory violation or that sort of thing but we assume that the application is sort of very well protected if you try to do a bad memory access, the system will trap and will throw the program out on the door, you know, out on its ear and that sort of thing. So what you do is the attacker tries a bunch of bad addresses. And it looks to see how long each failure took to report, right? So it times each failure. Sometimes the answer will come back right away, oh, that's a bad arrest. Other times it'll take somewhat longer. All these times are fairly short. We're talking, you know, nanoseconds versus microseconds. But as long as you have a high-resolution clock, you can now find out properties of a victim process. Why? Because the victim process will be doing some computation. That computation will involve putting something in the cache versus something in RAM. These cache accesses will be fast. The RAM accesses, of course, will be slow. What the bad address will do is it will sort of look up, you know, is this address okay? And what you can do if you're clever enough is have this address okay check depend on whether something is cached. So you can now snoop into the contents of some other process's cache, even though the hardware says you can't look at it. There's no direct access. The only access you actually have is you're doing your own stuff, you can see how long it takes. That's all you can do. But by observing how fast some of your invalid actions get detected, you can infer what the victim process is doing. There's a whole class of attacks that operate this way. This attack can work even if the attacker is running JavaScript code. And as I'm sure you know, JavaScript code is interpreted. It can be partially compiled, but it has a whole bunch of memory accesses and all that sort of thing checking built into it. You can't directly access anybody else's memory, but you can play this game even in JavaScript to find out what some other tab in the victim's browser is doing. The classes of attacks that I'm thinking of are called Spectre and Meltdown, and there's several others of this category and basically they exploit the fact that machines like to cash and they run a lot faster when they cash and we like speed so we want those caches to work how do you defend against this sort of thing well one option is turn off the cash now your programs run way slower but you're now defended against this. Almost nobody likes this solution, so there's now a bunch of hybrid solutions that selectively disable the cache. Another defense, here's a defense that Apple uses. Don't give people the time of day, right? This attack relies on having high-resolution clocks. Linux will give you the time of day to the nearest nanosecond, so you can do this attack on Linux. Mac OS only gives you the time of the day to the nearest microsecond, so it's harder to do these attacks. But then the cost is an Apple application can't do high resolution timing. If you're doing some application that needs high resolution timing, it won't run on Mac OS. Any comments on these forms of attacks? Have I left off your favorite form of attack? Yes. This one here? Well, for one thing, this came out in 2021. Oh, this whole general... Well, to some extent, I think part of the issue is, you know, these get a lot of press, but the attackers tend to think, this stuff is so easy, let's do this. We don't even have to rely on this high-tech stuff, right? Also, we're coming up with reasonably good defenses here. Intel, AMD, and ARM have all come up with defense, hardware defenses against this sort of attack in which they like fuzz timers and that sort of thing. So the assumption is this kind of attack, we'll figure out how to defeat it. These are gonna be with us forever, right? Other comments about these attacks, yes. Are there ever attacks where someone like, they send you an email, saying they're like a Nigerian thing? Do they have like design-- I've been around long enough that I have gotten actual physical mail from Nigeria from a Nigerian prince. It had cool stamps on it and all that sort of thing. I should have saved it just for the stamps, right? All right. So yeah, yeah, no, those sorts of attacks, those will always be with us as well. I hope nobody here falls for them. All right. So let me tell you one other kind of attack. And this attack appeared in a Turing Award lecture by Ken Thompson, all right? So we're talking somebody who's really smart, a lot smarter than I am and all that sort of thing, telling you how he might attack a system that's like Linux. Ken Thompson is one of the originators of Unix, which is an ancestor of Linux. So here's how he said he could attack one of the systems that he helped design and build. Here's the basic idea. He wants to be able to go to any Unix system, and he wants to be able to log in as Ken and not be asked for a password, and it immediately gives you a root prompt. And you can pick in any name you like. He picked Ken because that was his login name. He hated typing his password. Passwords just take too long. I'm the guy who designed the system. Just let me be root no matter what. Now obviously, the users of Unix didn't want this, right? So he said, here's my idea for letting me able to log into any Unix system as root, right? There's a login program. And it's written in C. And somewhere in that program, it looks at your name, and it looks at your password, and it checks it, right? And if it checks, then it says, okay, I'll let you in. And if it fails, it says no. So somewhere in this login program, there's sort of like this get name. Let's call that n equals get name. And then let p be get password. And then we will then look up the name. We'll get the password that that name is supposed to be used, and we'll do a string compare. Sort of like the code we already saw, right? Then, if all this is true, then, you know, let the person log in. So he said, well, since I wrote Unix, I can insert a security bug in the login program that will let me log in no matter what. So I'm going to write a buggy version. The buggy version will have an extra thing in here that just says if StericCMP can name equals equals zero, then, you know, log in okay. So I will write a buggy version of the Unix system. I'll distribute that to everybody who uses Unix and all that sort of thing and you know, we'll be off to the races now There's a problem with this approach Unix Originally was distributed with the open source model So you didn't distribute just the executable's and the object files You distributed the source code if he had done something like this to Unix Anybody who's reading the source code will look and say what what is this stuff going on here? I mean, somebody's trying to break in, right? So he knew this attack wouldn't work and came up with a variant of the attack that would have a better luck of working, right? What's the variant? Well, also in Unix was a C compiler. It wasn't GCC. It was their own compiler and that sort of thing. But it's the same basic idea. Here's the C compiler. here's the source code, it was called CC here's the source code to the C compiler it has a main program and all that sort of thing and so what he decided to do was to modify the C compiler to be something like this if the program name is login.c right then generate buggy code. And the buggy code that you generate is going to be this. So the idea is if we take the C compiler, we make this change. We have a buggy C compiler, right? And we take login.c. We don't need to change the source code to login.c. We can leave the source code alone. It looks like it's perfectly secure. But then when you compile it, you'll get a buggy login program. And you can ship Unix with the source code, the login.c, the executable for login, which is buggy. The source code is not buggy. And then the C compiler is buggy, right? But login, the source code is not. Now, you can object, and I think rightly so, that this approach just puts off the problem because what an auditor can do is now read the source code log in dot C looks good. There's no bug in the source code, but the C compiler is buggy, right? And the auditor will look at the C compiler and say, all right, you know, there's something bogus here. Let's go arrest Ken or something. So he had a solution for that as well. If we are compiling the C compiler, here let's generate a copy. We'll do all the things we normally do when we're generating the C compiler, but we'll generate a buggy C compiler. Over here, this is buggy login code. So generate buggy login code, in effect, inserts this source code as it's compiling, but then it's not really in the source code. It's just the C compiler thinks it's there. Similarly here, generate buggy CC code. What and pretends it's in the source code even when the source code isn't there. Now, all he has to do is compile the C compiler with itself, compile login with the C compiler. The executables will both have bugs. Login will have this bug. The C compiler will have this bug. And now he can ship the source code to the non-buggy C compiler, and the non-buggy login, Everybody who's auditing the source code will see everything's hunky-dory, and the executables are all wrong. All right, see how that works? Very clever. The title of his Turing Award talk, and I highly recommend it, it's the most readable Turing Award talk ever, is Reflections on Trusting Trust. I've given you, in some sense, a simplified version of what he actually did. What he actually did was, in some sense, more complicated, but in some sense was even easier than this. I read it and it was like trivial. It's like three lines of code or something. The guy's a genius, right? How do you defend yourself against this kind of software attack? Any thoughts? Well, here's an idea that doesn't work. Look at the executables with GDB. Disassemble the executables. Look at every machine instruction in the executable, read it and understand it and say, "Oh, what's this string compare doing here? Somebody is trying to break into the system. Why doesn't this defense mechanism work? Because he can modify CC to also plant a bug in GDB, right, if he's clever enough. And the guy is pretty clever. Right? So in some sense, what his point is, you have to trust somebody when you're building a secure system. The typical term for this is the trusted computing base. This is sort of the security perimeter. The stuff inside here is gonna be trusted. It might be, for example, the Linux kernel, a small set of applications, the hardware you're running on, that's it. And to some extent, there's always going to be a minimal set that you have to trust. You can't verify. because somebody could have played tricks like this on your verification technique. All right, anyhow, we have an exam coming up on Monday, right, so please come, and everything that we talked about in lecture is fair game, all of the assignments are fair game, your project is fair game, all the fun stuff we did in this class, we'll get to do it three more hours during the final, and I'll see you there.