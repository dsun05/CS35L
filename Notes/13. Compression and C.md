# Lecture Notes on Git Objects, Compression Algorithms, and Low-Level C Concepts

---

## 1. Git Internal Object Representation

### 1.1 Git Directory Structure

- Git creates a `.git/` subdirectory inside the repository directory.
- `.git/objects/` stores Git objects as files based on SHA-1 hashes.

### 1.2 Git Object File Naming

- Git represents each object by a 40-character hexadecimal string (SHA-1 checksum).
  - First 2 characters used as directory name.
  - Remaining 38 characters used as the file name inside the respective directory.
- Example:
  ```plaintext
  38-character: 6dcb09e
  2-character directory: 6d
  Object file inside: cb09e...
  ```

### 1.3 Blob Format

- One of Git's internal object types: `blob`, `tree`, and `commit`. Focus here is on `blob`.
- Format: `blob <size><null byte><binary contents>`:
  - ASCII `"blob"`, then a space.
  - Decimal count of number of bytes (e.g., `196`).
  - Null byte (`\0`) — one character with ASCII code 0.
  - Followed by `<size>` bytes (e.g., 196 bytes) as the blob content.

#### Why Include Size in Header?

- Even though redundant with the content length:
  - Blob format does not depend on external bookkeeping for size.
  - May be part of a packed structure hence needs self-description.

#### Why Use Decimal Characters for Length?

- Makes blobs somewhat readable for debugging.
- Using ASCII length makes developer debugging easier.
- Efficiency improvements are not worth added complexity in low-level binary parsing.

### 1.4 Compression in Git

- Git compresses objects using Zlib (same algorithm as Gzip).
- When examining files directly, decompression is required.

## 2. Limits and Theory of Data Compression

### 2.1 Fundamental Limits on Compression

- No "universal" or "general-purpose" compression algorithm that can always reduce file size.
- Compression must work based on patterns or redundancy.

#### Theoretical Background

- Given an input space of 2^N values:
  - No algorithm can losslessly encode all such values into strings smaller than N bits.
- Therefore, compression works only when:
  - The input has non-uniform patterns or redundancies.

### 2.2 Compression Behavior

| Input Type            | Compression Result                          |
|-----------------------|---------------------------------------------|
| Highly redundant text | Major size reduction                        |
| Random bytes          | Possibly larger due to added headers        |

## 3. Gzip/Zlib Compression Algorithms

Gzip combines:
1. Huffman Coding (1950s)
2. Dictionary Compression (1970s)

---

## 4. Huffman Coding

### 4.1 Overview

- Algorithm to assign variable-length bit strings to symbols based on frequencies.
- More frequent symbols get shorter bit codes.
- Optimal for symbol-by-symbol compression when symbol probabilities are known.

### 4.2 Example Symbol Probabilities

| Character | Frequency |
|-----------|-----------|
| `' '`     | 0.2       |
| `e`       | 0.06      |
| `t`       | Less than `e` |
| `z/q`     | Very rare |

### 4.3 Encoding Table Structure

| Symbol | Encoding  |
|--------|-----------|
| space  | 00        |
| e      | 01        |
| t      | 10        |
| q      | 11100101  |

- Must satisfy **prefix-free** condition:
  - No code may be prefix of another.

### 4.4 Huffman Tree Construction

- Start with all symbols as leaves, ordered by frequency.
- Merge two least frequent symbols at each step.
- Repeat until one node (the root) remains.
- Path from root to a leaf forms the codeword for symbol.

| Node      | Frequency |
|-----------|-----------|
| Q         | 0.0001    |
| Z         | 0.0002    |
| QZ        | 0.0003    |
| ...       | ...       |

- Each merge reduces number of active nodes by 1.
- Total nodes:
  - 256 leaves → 255 internal nodes.

### 4.5 Optimality & Limitations

#### Pros

- Minimizes total bits assuming:
  - Known, fixed symbol probabilities.

#### Cons

- Requires both sender and receiver to know the same encoding table.
- Table size adds overhead.
- Inflexible if input corpus changes (e.g., switches languages mid-text).

---

## 5. Adaptive Huffman Coding

### 5.1 Overview

- Sender and receiver start with trivial, balanced Huffman tree.
- Tree updated dynamically based on input symbols.
- No need to transmit the full table upfront.

### 5.2 Process

1. Start with uniform tree (equal frequency).
2. Transmit first few symbols in full (e.g., 8-bit bytes).
3. After each symbol:
   - Update tree.
   - Both sender and receiver maintain identical updated trees.

### 5.3 Advantages

- Only one pass over input required.
- Efficient over time as tree reflects input statistics better.
- Dynamically adjusts to changes in symbol distribution.

### 5.4 Trade-Offs

- Inefficient at start.
- Slightly suboptimal compared to full-table Huffman.
- Sender/receiver must maintain and synchronize tree via a shared update algorithm (e.g., rebalancing with frequency updates).

---

## 6. Dictionary Compression

### 6.1 Basic Idea

- Replace frequent sequences of bytes (e.g., words) with short codes.
- Instead of encoding each byte, encode entire sequences.

### 6.2 Dictionary Setup

- Build dictionary:
  ```plaintext
  Index | Value
  ------|------------------
  1     | "the "
  2     | "and"
  3     | "understandable"
  ```
- Data stream encodes sequences as index references.
- E.g., "understandable" → index 3, 16-bit code.

### 6.3 Issues & Considerations

1. What if dictionary is too large?
   - e.g., full English dictionary > 100,000 entries.
2. How are non-word characters handled?
   - Dictionary includes not just words; includes all common byte sequences.

---

## 7. Adaptive Dictionary Compression

### 7.1 Problem

- Non-adaptive method requires:
  - First pass: build dictionary.
  - Second pass: encode using dictionary.
- Not ideal due to multiple passes or large memory usage.

### 7.2 Adaptive Approach

- Uses a **sliding window** dictionary.
- Sender and receiver both maintain a history of previous N bytes (usually 64KiB).
- Dictionary dynamically reflects recent input.
- Format for reference:
  ```plaintext
  {Offset (16 bits), Length (8 bits)}
  ```

### 7.3 Compression Technique

1. Start with empty dictionary.
2. At each input point:
   - Find longest match in dictionary.
   - Emit (offset, length).
3. If no match:
   - Emit raw byte.

### 7.4 Search Optimization

- Naive search: O(n²).
- Efficient implementation uses:
  - Trie or suffix tree structure.
  - Performance is improved to O(n log n).

### 7.5 Sample Table

| Word           | Offset | Length |
|----------------|--------|--------|
| "understandable" | 14000  | 13     |
| "the"          | 22000  | 3      |
| "QZ"           | 30000  | 2      |

### 7.6 Limitations

- If a matching sequence no longer exists in the sliding window, it must be sent as a raw byte.
- Random data sequences compress poorly.
- Sensitive to any data loss — losing synchronization causes downstream errors.

---

## 8. Programming in C vs. C++

### 8.1 Simplified View: C = C++ - High-Level Features

| Feature                | C++ | C     |
|------------------------|-----|-------|
| Classes & Objects      | Yes | No    |
| Polymorphism           | Yes | No    |
| Encapsulation          | Yes | Limited |
| Inheritance            | Yes | No    |
| Abstract Data Types    | Yes | Less supported |
| Static Members         | Yes | Not in structs |
| Namespaces             | Yes | No    |
| Function Overloading   | Yes | No    |
| Exceptions             | Yes | No (discouraged) |
| New/Delete             | Yes | No (use malloc/free) |
| `cin`/`cout`           | Yes | No (use `stdio.h`) |

---

## 9. C Compilation Process

### 9.1 Compilation Steps

| Step           | Input  | Output  | GCC Flag        |
|----------------|--------|---------|-----------------|
| Preprocessing  | .c     | .i      | `-E`            |
| Compilation    | .i     | .s      | `-S`            |
| Assembly       | .s     | .o      | `-c`            |
| Linking        | .o     | (executable) | -o (with `gcc`) |

### 9.2 Example

```c
#define INTMAX 2147483647
int main() { return INTMAX; }
```

→ Preprocessing:

```c
int main() { return 2147483647; }
```

→ Assembly:

```asm
main:
    movl $2147483647, %eax
    ret
```

→ Linking involves replacing placeholder calls (e.g., `abs`) with library addresses.

---

## 10. Process Management & Developer Tools

### 10.1 Process Management Commands

| Command        | Purpose                                 |
|----------------|------------------------------------------|
| `ps`           | Show running processes                   |
| `ps -ef`       | All processes (full view)                |
| `ps -ejH`      | Show hierarchy of processes              |
| `kill <PID>`   | Send default signal (TERM)               |
| `kill -9 <PID>`| Force kill using SIGKILL signal          |
| `kill -STOP`   | Pause process                            |
| `kill -CONT`   | Resume process                           |

### 10.2 Debugging Tools

#### 1. `time <command>`

- Shows:
  - Real time: actual elapsed wall-clock time.
  - User time: CPU time in user space.
  - Sys time: CPU time in kernel space.

#### 2. `strace <command>`

- Traces **system calls** (interactions with the kernel).
- Useful for understanding file access, network, etc.

#### 3. `ltrace <command>`

- Traces **library calls** (e.g., `printf`, `malloc`).
- Useful for monitoring interaction with C standard library.

#### 4. `valgrind <command>`

- Memory error detection tool.
- Detects:
  - Invalid memory access.
  - Memory leaks.
  - Use of uninitialized variables.
- Slower but more exhaustive than standard execution.

---

## Summary

This lecture explored Git's internal object model, specifically the storage and format of blob objects, and explained how Git compresses data using the same algorithms as Gzip/Zlib. It provided a deep dive into compression theory, highlighting the limits of general-purpose compression and the two main strategies employed in Gzip: Huffman coding and dictionary compression. Both static and adaptive versions of these algorithms were explained with implementation examples.

The lecture also transitioned into the world of low-level C programming, contrasting it with C++ by highlighting the features C omits for greater control and performance. This included a walk-through of the C compilation pipeline and the tools developers use to observe and manage processes, debug, and track system and memory behavior. These tools and concepts are essential for understanding system-level programming and preparing for upcoming assignments that work closely with system internals.